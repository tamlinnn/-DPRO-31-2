import pyspark.sql.functions as F
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Covid Data Analysis").getOrCreate()

# Загрузка данных
df = spark.read.csv('covid-data.csv', header=True)

# Фильтрация данных по дате
df = df.filter(df['location'] != 'World')
df = df.filter(df['date'] <= '2021-03-31')
df = df.filter(df['date'] > '2021-03-29')

# Группировка данных по странам и датам
grouped_df = df.groupBy('location').agg(F.sum('new_cases').alias('new_cases'))

# Сортировка стран по количеству новых случаев
sorted_df = grouped_df.sort('new_cases', ascending=False)
sorted_df = sorted_df.filter(sorted_df['location'] != 'World')

# Выбор первых 10 строк
top_10_countries = sorted_df.limit(10)

# Вывод результатов
top_10_countries.show()


